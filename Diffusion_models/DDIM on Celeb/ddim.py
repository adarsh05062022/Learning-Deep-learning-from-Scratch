# -*- coding: utf-8 -*-
"""DDIM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LeXbmj7nZotG7oQuXOUHS6rhDt8W6yyd
"""

import math
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, utils
import numpy as np
import matplotlib.pyplot as plt
import os
from tqdm import tqdm
import SinusoidalPosEmb
from module import BigUNet
from util import save_images
from util import ImageFolderFlat


# -----------------------
# Config / Hyperparams
# -----------------------

DATA_ROOT = "/storage/s25017/Datasets/img_align_celeba/img_align_celeba" 
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
BATCH_SIZE = 64
IMAGE_SIZE = 64
CHANNELS = 3
T = 1000                          # training diffusion length
EPOCHS = 50                        # increase for better quality
LR = 2e-4
SAVE_DIR = "ddim_celeb_checkpoints"
os.makedirs(SAVE_DIR, exist_ok=True)

# -----------------------
# Utilities
# -----------------------
def set_seed(seed=42):
    import random, numpy as _np
    torch.manual_seed(seed); _np.random.seed(seed); random.seed(seed)

set_seed(42)

# Sinusoidal timestep embedding (like Transformer / DDPM)

# ---------- small utilities ----------

    
# -----------------------
# Beta schedule & helpers
# -----------------------
def linear_beta_schedule(timesteps, beta_start=1e-4, beta_end=0.02):
    return torch.linspace(beta_start, beta_end, timesteps)

betas = linear_beta_schedule(T).to(DEVICE)      # (T,)
alphas = 1.0 - betas
alphas_cumprod = torch.cumprod(alphas, dim=0)   # \bar{alpha}_t
sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)
sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - alphas_cumprod)

# helper to index into precomputed arrays (broadcast for images)
def get_scalar(arr, t, x_shape):
    """arr: 1D tensor length T, t: int or tensor (B,), x_shape = (B,C,H,W)"""
    if isinstance(t, int):
        v = arr[t]
        return v.view(1,1,1,1)
    else:
        t = t.long()
        vals = arr[t].view(-1,1,1,1)
        return vals

# -----------------------
# Dataset
# -----------------------
transform = transforms.Compose([
    transforms.Resize(IMAGE_SIZE, interpolation=transforms.InterpolationMode.BICUBIC),
    transforms.CenterCrop(IMAGE_SIZE),
    transforms.Lambda(lambda img: img.convert("RGB")),   # force RGB
    transforms.ToTensor(),                                # [0,1]
    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3),      # [-1,1]
])

train_ds = ImageFolderFlat(root=DATA_ROOT, transform=transform)
train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True,drop_last=True)

# -----------------------
# Training loop (simple eps prediction)
# -----------------------
def train(model, optimizer, epochs=EPOCHS):
    model.train()
    step = 0
    for ep in range(epochs):
        pbar = tqdm(train_loader, desc=f"Epoch {ep+1}/{epochs}")
        for imgs in pbar:
            imgs = imgs.to(DEVICE)   # [-1,1]
            b = imgs.shape[0]
            # sample random timesteps in [0, T-1]
            t = torch.randint(0, T, (b,), device=DEVICE)
            # sample noise
            eps = torch.randn_like(imgs)
            # compute x_t from x0
            sqrt_ab = get_scalar(sqrt_alphas_cumprod, t, imgs.shape).to(DEVICE)
            sqrt_1_ab = get_scalar(sqrt_one_minus_alphas_cumprod, t, imgs.shape).to(DEVICE)
            x_t = sqrt_ab * imgs + sqrt_1_ab * eps

            # predict eps
            eps_pred = model(x_t, t)

            loss = F.mse_loss(eps_pred, eps)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            step += 1
            if step % 200 == 0:
                # print a tiny status
                pbar.set_postfix({"loss": loss.item()})
        # save checkpoint each epoch
        if ep%5==0:
            torch.save(model.state_dict(), os.path.join(SAVE_DIR, f"ckpt_epoch_{ep:03d}.pt"))

        # Sample with DDIM (deterministic)
        print("Sampling with DDIM (50 steps, eta=0.0)...")
        samples = ddim_sample(model, batch_size=64, num_steps=50, eta=0.0)
        save_images(samples, nrow=8, filename=f"epoch_{ep:03d}_ddim50.png", save_dir="results")
    return model

# -----------------------
# DDIM sampler
# -----------------------
def make_ddim_timesteps(T, num_steps):
    # pick num_steps evenly spaced indices from [0..T-1], descending
    assert num_steps <= T
    skip = T // num_steps
    seq = list(range(0, T, skip))
    if seq[-1] != T-1:
        seq.append(T-1)
    seq = sorted(list(set(seq)))
    seq = seq[::-1]  # descending
    return seq

def ddim_sample(model, batch_size=16, num_steps=50, eta=0.0):
    """
    model: trained epsilon model
    num_steps: number of DDIM steps to take (<= T)
    eta: 0.0 deterministic DDIM, >0 adds noise
    """
    model.eval()
    timesteps = make_ddim_timesteps(T, num_steps)  # descending list
    device = next(model.parameters()).device

    # initial noise x_T
    x = torch.randn(batch_size, CHANNELS, IMAGE_SIZE, IMAGE_SIZE, device=device)

    with torch.no_grad():
        for i in range(len(timesteps)-1):
            t = timesteps[i]
            t_prev = timesteps[i+1]

            # predict eps
            t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.long)
            eps_theta = model(x, t_tensor)

            # estimate x0
            sa_t = get_scalar(sqrt_alphas_cumprod, t, x.shape).to(device)
            soa_t = get_scalar(sqrt_one_minus_alphas_cumprod, t, x.shape).to(device)
            x0_pred = (x - soa_t * eps_theta) / sa_t

            # compute coefficients for x_{t-1}
            sa_t_prev = get_scalar(sqrt_alphas_cumprod, t_prev, x.shape).to(device)
            # compute sigma_t for stochasticity (DDIM paper formula)
            alpha_bar_t = alphas_cumprod[t]
            alpha_bar_t_prev = alphas_cumprod[t_prev]
            alpha_t = alphas[t]
            alpha_t_prev = alphas[t_prev]
            # numeric versions:
            # sigma_t term (as in DDIM paper)
            sigma_t = eta * math.sqrt((1 - alpha_bar_t_prev) / (1 - alpha_bar_t) * (1 - alpha_t / alpha_t_prev))
            sigma_t = float(sigma_t)

            # deterministic coeff on eps_theta
            coeff_eps = math.sqrt(1 - alpha_bar_t_prev - sigma_t**2)
            coeff_eps = torch.tensor(coeff_eps, device=device).view(1,1,1,1)

            x = sa_t_prev * x0_pred + coeff_eps * eps_theta
            if sigma_t > 0:
                noise = torch.randn_like(x) * sigma_t
                x = x + noise

    # final x is approx x_0 (in [-1,1])
    return x


# -----------------------
# Main: train a bit and sample
# -----------------------
def main():
    model = BigUNet(in_channels=CHANNELS).to(DEVICE)
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)

    print("Training model (this may take a while depending on EPOCHS)...")
    train(model, optimizer, epochs=EPOCHS)

    # Save final model
    save_path = os.path.join(SAVE_DIR, "model_final.pt")
    torch.save(model.state_dict(), save_path)
    print("Saved model to", save_path)

    

main()