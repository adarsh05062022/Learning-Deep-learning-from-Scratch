/data1/adarsh/MODEL_TRAINING/GAN/CycleGAN/utils.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_file, map_location=config.DEVICE)
/data1/adarsh/MODEL_TRAINING/GAN/CycleGAN/train.py:149: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  g_scaler = torch.cuda.amp.GradScaler()
/data1/adarsh/MODEL_TRAINING/GAN/CycleGAN/train.py:150: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  d_scaler = torch.cuda.amp.GradScaler()
=> Loading checkpoint
=> Loading checkpoint
=> Loading checkpoint
=> Loading checkpoint

Epoch [1/30]
/data1/adarsh/MODEL_TRAINING/GAN/CycleGAN/train.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/data1/adarsh/MODEL_TRAINING/GAN/CycleGAN/train.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch [1/30] Step [0/334] H_real=0.706, H_fake=0.384 D_loss=0.2770, G_loss=4.0615
Epoch [1/30] Step [100/334] H_real=0.600, H_fake=0.393 D_loss=0.3358, G_loss=3.7054
Epoch [1/30] Step [200/334] H_real=0.601, H_fake=0.391 D_loss=0.3716, G_loss=4.2721
Epoch [1/30] Step [300/334] H_real=0.602, H_fake=0.394 D_loss=0.3914, G_loss=3.5759
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [2/30]
Epoch [2/30] Step [0/334] H_real=0.682, H_fake=0.383 D_loss=0.3547, G_loss=3.8875
Epoch [2/30] Step [100/334] H_real=0.595, H_fake=0.392 D_loss=0.3732, G_loss=3.6064
Epoch [2/30] Step [200/334] H_real=0.604, H_fake=0.386 D_loss=0.3762, G_loss=3.4722
Epoch [2/30] Step [300/334] H_real=0.603, H_fake=0.390 D_loss=0.4549, G_loss=3.9421
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [3/30]
Epoch [3/30] Step [0/334] H_real=0.528, H_fake=0.373 D_loss=0.4013, G_loss=3.6533
Epoch [3/30] Step [100/334] H_real=0.605, H_fake=0.391 D_loss=0.3803, G_loss=3.7793
Epoch [3/30] Step [200/334] H_real=0.608, H_fake=0.388 D_loss=0.2813, G_loss=3.6501
Epoch [3/30] Step [300/334] H_real=0.605, H_fake=0.389 D_loss=0.4122, G_loss=3.4491
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [4/30]
Epoch [4/30] Step [0/334] H_real=0.618, H_fake=0.425 D_loss=0.3693, G_loss=3.2430
Epoch [4/30] Step [100/334] H_real=0.612, H_fake=0.389 D_loss=0.3255, G_loss=3.6771
Epoch [4/30] Step [200/334] H_real=0.606, H_fake=0.390 D_loss=0.4159, G_loss=3.8062
Epoch [4/30] Step [300/334] H_real=0.607, H_fake=0.390 D_loss=0.3433, G_loss=3.9925
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [5/30]
Epoch [5/30] Step [0/334] H_real=0.545, H_fake=0.391 D_loss=0.3646, G_loss=3.4479
Epoch [5/30] Step [100/334] H_real=0.608, H_fake=0.383 D_loss=0.3766, G_loss=3.5536
Epoch [5/30] Step [200/334] H_real=0.607, H_fake=0.386 D_loss=0.2956, G_loss=3.6626
Epoch [5/30] Step [300/334] H_real=0.606, H_fake=0.387 D_loss=0.3265, G_loss=3.4146
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [6/30]
Epoch [6/30] Step [0/334] H_real=0.567, H_fake=0.458 D_loss=0.4479, G_loss=3.4628
Epoch [6/30] Step [100/334] H_real=0.604, H_fake=0.385 D_loss=0.3230, G_loss=3.6014
Epoch [6/30] Step [200/334] H_real=0.605, H_fake=0.386 D_loss=0.2681, G_loss=3.7684
Epoch [6/30] Step [300/334] H_real=0.607, H_fake=0.386 D_loss=0.3155, G_loss=3.3908
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [7/30]
Epoch [7/30] Step [0/334] H_real=0.654, H_fake=0.466 D_loss=0.4340, G_loss=3.4609
Epoch [7/30] Step [100/334] H_real=0.613, H_fake=0.386 D_loss=0.4317, G_loss=3.3862
Epoch [7/30] Step [200/334] H_real=0.605, H_fake=0.387 D_loss=0.4066, G_loss=3.6001
Epoch [7/30] Step [300/334] H_real=0.610, H_fake=0.385 D_loss=0.2964, G_loss=3.5718
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [8/30]
Epoch [8/30] Step [0/334] H_real=0.773, H_fake=0.416 D_loss=0.2709, G_loss=3.5772
Epoch [8/30] Step [100/334] H_real=0.613, H_fake=0.387 D_loss=0.3631, G_loss=3.5255
Epoch [8/30] Step [200/334] H_real=0.613, H_fake=0.384 D_loss=0.3999, G_loss=3.5161
Epoch [8/30] Step [300/334] H_real=0.612, H_fake=0.383 D_loss=0.3645, G_loss=3.4489
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [9/30]
Epoch [9/30] Step [0/334] H_real=0.611, H_fake=0.387 D_loss=0.3229, G_loss=4.1270
Epoch [9/30] Step [100/334] H_real=0.605, H_fake=0.391 D_loss=0.3889, G_loss=3.2938
Epoch [9/30] Step [200/334] H_real=0.605, H_fake=0.389 D_loss=0.3988, G_loss=3.5478
Epoch [9/30] Step [300/334] H_real=0.608, H_fake=0.386 D_loss=0.3947, G_loss=3.2255
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [10/30]
Epoch [10/30] Step [0/334] H_real=0.553, H_fake=0.347 D_loss=0.3597, G_loss=3.7266
Epoch [10/30] Step [100/334] H_real=0.612, H_fake=0.376 D_loss=0.3853, G_loss=3.3803
Epoch [10/30] Step [200/334] H_real=0.610, H_fake=0.383 D_loss=0.3176, G_loss=3.9365
Epoch [10/30] Step [300/334] H_real=0.609, H_fake=0.383 D_loss=0.3429, G_loss=3.7720
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [11/30]
Epoch [11/30] Step [0/334] H_real=0.730, H_fake=0.418 D_loss=0.2716, G_loss=3.4285
Epoch [11/30] Step [100/334] H_real=0.614, H_fake=0.387 D_loss=0.3039, G_loss=3.5480
Epoch [11/30] Step [200/334] H_real=0.614, H_fake=0.384 D_loss=0.3921, G_loss=3.3390
Epoch [11/30] Step [300/334] H_real=0.611, H_fake=0.383 D_loss=0.3081, G_loss=3.3999
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [12/30]
Epoch [12/30] Step [0/334] H_real=0.666, H_fake=0.438 D_loss=0.3467, G_loss=3.1739
Epoch [12/30] Step [100/334] H_real=0.613, H_fake=0.379 D_loss=0.2707, G_loss=3.3584
Epoch [12/30] Step [200/334] H_real=0.611, H_fake=0.380 D_loss=0.3563, G_loss=3.3807
Epoch [12/30] Step [300/334] H_real=0.610, H_fake=0.379 D_loss=0.2978, G_loss=4.1148
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [13/30]
Epoch [13/30] Step [0/334] H_real=0.612, H_fake=0.423 D_loss=0.3725, G_loss=3.4511
Epoch [13/30] Step [100/334] H_real=0.614, H_fake=0.379 D_loss=0.3823, G_loss=3.8837
Epoch [13/30] Step [200/334] H_real=0.615, H_fake=0.382 D_loss=0.3004, G_loss=4.2399
Epoch [13/30] Step [300/334] H_real=0.615, H_fake=0.381 D_loss=0.3818, G_loss=3.8621
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [14/30]
Epoch [14/30] Step [0/334] H_real=0.609, H_fake=0.415 D_loss=0.3840, G_loss=3.0887
Epoch [14/30] Step [100/334] H_real=0.615, H_fake=0.387 D_loss=0.2623, G_loss=3.2521
Epoch [14/30] Step [200/334] H_real=0.613, H_fake=0.385 D_loss=0.3355, G_loss=3.3175
Epoch [14/30] Step [300/334] H_real=0.617, H_fake=0.380 D_loss=0.3372, G_loss=3.0357
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [15/30]
Epoch [15/30] Step [0/334] H_real=0.587, H_fake=0.381 D_loss=0.3416, G_loss=3.4365
Epoch [15/30] Step [100/334] H_real=0.608, H_fake=0.388 D_loss=0.3709, G_loss=2.8892
Epoch [15/30] Step [200/334] H_real=0.612, H_fake=0.386 D_loss=0.4494, G_loss=3.2782
Epoch [15/30] Step [300/334] H_real=0.614, H_fake=0.383 D_loss=0.3408, G_loss=3.7988
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [16/30]
Epoch [16/30] Step [0/334] H_real=0.627, H_fake=0.429 D_loss=0.3984, G_loss=3.6623
Epoch [16/30] Step [100/334] H_real=0.618, H_fake=0.379 D_loss=0.3969, G_loss=3.2684
Epoch [16/30] Step [200/334] H_real=0.615, H_fake=0.380 D_loss=0.3299, G_loss=3.4567
Epoch [16/30] Step [300/334] H_real=0.615, H_fake=0.382 D_loss=0.3442, G_loss=3.4571
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [17/30]
Epoch [17/30] Step [0/334] H_real=0.632, H_fake=0.347 D_loss=0.3210, G_loss=3.8101
Epoch [17/30] Step [100/334] H_real=0.614, H_fake=0.381 D_loss=0.4085, G_loss=3.5942
Epoch [17/30] Step [200/334] H_real=0.615, H_fake=0.381 D_loss=0.3449, G_loss=3.6820
Epoch [17/30] Step [300/334] H_real=0.613, H_fake=0.383 D_loss=0.3802, G_loss=3.5042
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [18/30]
Epoch [18/30] Step [0/334] H_real=0.622, H_fake=0.398 D_loss=0.3099, G_loss=3.3648
Epoch [18/30] Step [100/334] H_real=0.607, H_fake=0.380 D_loss=0.3653, G_loss=3.2935
Epoch [18/30] Step [200/334] H_real=0.609, H_fake=0.383 D_loss=0.3491, G_loss=3.1040
Epoch [18/30] Step [300/334] H_real=0.612, H_fake=0.383 D_loss=0.3421, G_loss=3.2577
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [19/30]
Epoch [19/30] Step [0/334] H_real=0.635, H_fake=0.328 D_loss=0.3234, G_loss=3.6161
Epoch [19/30] Step [100/334] H_real=0.610, H_fake=0.381 D_loss=0.4199, G_loss=3.5092
Epoch [19/30] Step [200/334] H_real=0.611, H_fake=0.382 D_loss=0.4124, G_loss=3.6395
Epoch [19/30] Step [300/334] H_real=0.613, H_fake=0.382 D_loss=0.3027, G_loss=3.2379
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [20/30]
Epoch [20/30] Step [0/334] H_real=0.589, H_fake=0.396 D_loss=0.3587, G_loss=4.0296
Epoch [20/30] Step [100/334] H_real=0.615, H_fake=0.375 D_loss=0.4345, G_loss=3.4311
Epoch [20/30] Step [200/334] H_real=0.612, H_fake=0.381 D_loss=0.3489, G_loss=3.3387
Epoch [20/30] Step [300/334] H_real=0.610, H_fake=0.383 D_loss=0.3786, G_loss=3.1042
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [21/30]
Epoch [21/30] Step [0/334] H_real=0.731, H_fake=0.410 D_loss=0.2952, G_loss=3.6630
Epoch [21/30] Step [100/334] H_real=0.617, H_fake=0.379 D_loss=0.2909, G_loss=3.1543
Epoch [21/30] Step [200/334] H_real=0.610, H_fake=0.384 D_loss=0.3089, G_loss=3.8270
Epoch [21/30] Step [300/334] H_real=0.612, H_fake=0.382 D_loss=0.3210, G_loss=3.5131
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [22/30]
Epoch [22/30] Step [0/334] H_real=0.585, H_fake=0.404 D_loss=0.3805, G_loss=3.5385
Epoch [22/30] Step [100/334] H_real=0.612, H_fake=0.380 D_loss=0.4001, G_loss=3.8323
Epoch [22/30] Step [200/334] H_real=0.610, H_fake=0.384 D_loss=0.4004, G_loss=3.5557
Epoch [22/30] Step [300/334] H_real=0.610, H_fake=0.383 D_loss=0.2819, G_loss=3.2701
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [23/30]
Epoch [23/30] Step [0/334] H_real=0.523, H_fake=0.351 D_loss=0.3749, G_loss=3.6289
Epoch [23/30] Step [100/334] H_real=0.610, H_fake=0.385 D_loss=0.3046, G_loss=2.9982
Epoch [23/30] Step [200/334] H_real=0.612, H_fake=0.382 D_loss=0.3192, G_loss=3.2217
Epoch [23/30] Step [300/334] H_real=0.613, H_fake=0.381 D_loss=0.2888, G_loss=3.0194
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [24/30]
Epoch [24/30] Step [0/334] H_real=0.685, H_fake=0.316 D_loss=0.2830, G_loss=3.6181
Epoch [24/30] Step [100/334] H_real=0.615, H_fake=0.382 D_loss=0.3790, G_loss=3.4274
Epoch [24/30] Step [200/334] H_real=0.612, H_fake=0.383 D_loss=0.3415, G_loss=3.1477
Epoch [24/30] Step [300/334] H_real=0.611, H_fake=0.386 D_loss=0.2435, G_loss=3.4784
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [25/30]
Epoch [25/30] Step [0/334] H_real=0.530, H_fake=0.348 D_loss=0.3691, G_loss=3.2163
Epoch [25/30] Step [100/334] H_real=0.613, H_fake=0.377 D_loss=0.3194, G_loss=3.4453
Epoch [25/30] Step [200/334] H_real=0.615, H_fake=0.380 D_loss=0.2725, G_loss=3.3439
Epoch [25/30] Step [300/334] H_real=0.614, H_fake=0.381 D_loss=0.4361, G_loss=3.1676
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [26/30]
Epoch [26/30] Step [0/334] H_real=0.653, H_fake=0.491 D_loss=0.4450, G_loss=3.1219
Epoch [26/30] Step [100/334] H_real=0.613, H_fake=0.385 D_loss=0.3495, G_loss=3.4818
Epoch [26/30] Step [200/334] H_real=0.614, H_fake=0.384 D_loss=0.3679, G_loss=3.2564
Epoch [26/30] Step [300/334] H_real=0.613, H_fake=0.382 D_loss=0.3649, G_loss=3.1773
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [27/30]
Epoch [27/30] Step [0/334] H_real=0.565, H_fake=0.366 D_loss=0.3709, G_loss=2.8697
Epoch [27/30] Step [100/334] H_real=0.617, H_fake=0.382 D_loss=0.2967, G_loss=3.3306
Epoch [27/30] Step [200/334] H_real=0.615, H_fake=0.382 D_loss=0.3587, G_loss=3.1532
Epoch [27/30] Step [300/334] H_real=0.613, H_fake=0.381 D_loss=0.4101, G_loss=3.5128
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [28/30]
Epoch [28/30] Step [0/334] H_real=0.595, H_fake=0.414 D_loss=0.3420, G_loss=3.3286
Epoch [28/30] Step [100/334] H_real=0.621, H_fake=0.378 D_loss=0.2144, G_loss=3.3306
Epoch [28/30] Step [200/334] H_real=0.615, H_fake=0.379 D_loss=0.4301, G_loss=3.2298
Epoch [28/30] Step [300/334] H_real=0.613, H_fake=0.381 D_loss=0.3757, G_loss=3.1082
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [29/30]
Epoch [29/30] Step [0/334] H_real=0.603, H_fake=0.392 D_loss=0.3777, G_loss=3.1891
Epoch [29/30] Step [100/334] H_real=0.606, H_fake=0.387 D_loss=0.2597, G_loss=3.3441
Epoch [29/30] Step [200/334] H_real=0.607, H_fake=0.387 D_loss=0.3503, G_loss=3.4690
Epoch [29/30] Step [300/334] H_real=0.611, H_fake=0.384 D_loss=0.2715, G_loss=3.0083
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint

Epoch [30/30]
Epoch [30/30] Step [0/334] H_real=0.573, H_fake=0.411 D_loss=0.3755, G_loss=3.4281
Epoch [30/30] Step [100/334] H_real=0.616, H_fake=0.381 D_loss=0.2769, G_loss=3.2090
Epoch [30/30] Step [200/334] H_real=0.613, H_fake=0.385 D_loss=0.3871, G_loss=2.9646
Epoch [30/30] Step [300/334] H_real=0.613, H_fake=0.383 D_loss=0.3685, G_loss=3.4295
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
=> Saving checkpoint
