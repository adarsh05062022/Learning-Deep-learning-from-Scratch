{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:02:45.797161Z","iopub.execute_input":"2025-09-05T07:02:45.797465Z","iopub.status.idle":"2025-09-05T07:02:48.243341Z","shell.execute_reply.started":"2025-09-05T07:02:45.797415Z","shell.execute_reply":"2025-09-05T07:02:48.241952Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:44:30.614739Z","iopub.execute_input":"2025-09-05T07:44:30.615263Z","iopub.status.idle":"2025-09-05T07:44:30.620709Z","shell.execute_reply.started":"2025-09-05T07:44:30.615231Z","shell.execute_reply":"2025-09-05T07:44:30.619546Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"df = pd.DataFrame([[8,8,4],[7,9,5],[6,10,6],[5,12,7]], columns=['cgpa', 'profile_score', 'lpa'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:44:32.258195Z","iopub.execute_input":"2025-09-05T07:44:32.258610Z","iopub.status.idle":"2025-09-05T07:44:32.265647Z","shell.execute_reply.started":"2025-09-05T07:44:32.258574Z","shell.execute_reply":"2025-09-05T07:44:32.264471Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"def initialize_parameters(layer_dims):\n    np.random.seed(3)\n    parameters = {}\n    L = len(layer_dims)\n    for l in range(1,L):\n        parameters['W' + str(l)] = np.ones((layer_dims[l-1], layer_dims[l]))*0.1\n        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n    return parameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:44:35.574541Z","iopub.execute_input":"2025-09-05T07:44:35.574892Z","iopub.status.idle":"2025-09-05T07:44:35.581204Z","shell.execute_reply.started":"2025-09-05T07:44:35.574860Z","shell.execute_reply":"2025-09-05T07:44:35.580138Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"def linear_forward(A_prev, W, b):\n  \n  Z = np.dot(W.T, A_prev) + b\n  \n  return Z","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:44:40.683151Z","iopub.execute_input":"2025-09-05T07:44:40.683464Z","iopub.status.idle":"2025-09-05T07:44:40.688916Z","shell.execute_reply.started":"2025-09-05T07:44:40.683422Z","shell.execute_reply":"2025-09-05T07:44:40.687639Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"def L_layer_forward(X,parameters):\n\n    A = X\n    L = len(parameters) // 2\n    for l in range(1,L):\n        \n        A_prev = A\n        Wl = parameters[\"W\" + str(l)]\n        bl = parameters[\"b\" + str(l)]\n        A = linear_forward(A_prev,Wl,bl)\n\n    return A,A_prev\n                ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:45:28.849911Z","iopub.execute_input":"2025-09-05T07:45:28.850251Z","iopub.status.idle":"2025-09-05T07:45:28.856286Z","shell.execute_reply.started":"2025-09-05T07:45:28.850227Z","shell.execute_reply":"2025-09-05T07:45:28.855223Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"def update_parameters(parameters,y,y_hat,A1,X):\n  parameters['W2'][0][0] = parameters['W2'][0][0] + (0.001 * 2 * (y - y_hat)*A1[0][0])\n  parameters['W2'][1][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat)*A1[1][0])\n  parameters['b2'][0][0] = parameters['W2'][1][0] + (0.001 * 2 * (y - y_hat))\n\n  parameters['W1'][0][0] = parameters['W1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[0][0])\n  parameters['W1'][0][1] = parameters['W1'][0][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0]*X[1][0])\n  parameters['b1'][0][0] = parameters['b1'][0][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][0][0])\n\n  parameters['W1'][1][0] = parameters['W1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[0][0])\n  parameters['W1'][1][1] = parameters['W1'][1][1] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]*X[1][0])\n  parameters['b1'][1][0] = parameters['b1'][1][0] + (0.001 * 2 * (y - y_hat)*parameters['W2'][1][0]) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:45:36.985517Z","iopub.execute_input":"2025-09-05T07:45:36.985834Z","iopub.status.idle":"2025-09-05T07:45:36.995722Z","shell.execute_reply.started":"2025-09-05T07:45:36.985811Z","shell.execute_reply":"2025-09-05T07:45:36.994626Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"parameters = initialize_parameters([2,2,1])\nprint(parameters)\nfor i in range(len(df)):\n    X = df[['cgpa', 'profile_score']].values[i].reshape(2,1) # Shape(no of features, no. of training example)\n    y = df[['lpa']].values[i][0]\n    \n    # Parameter initialization\n\n    \n    y_hat,A1 = L_layer_forward(X,parameters)\n    y_hat = y_hat[0][0]\n    \n    update_parameters(parameters,y,y_hat,A1,X)\n    print(f\"For row = {i+1}\")\n    print(parameters)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:46:08.542580Z","iopub.execute_input":"2025-09-05T07:46:08.542899Z","iopub.status.idle":"2025-09-05T07:46:08.557640Z","shell.execute_reply.started":"2025-09-05T07:46:08.542879Z","shell.execute_reply":"2025-09-05T07:46:08.556565Z"}},"outputs":[{"name":"stdout","text":"{'W1': array([[0.1, 0.1],\n       [0.1, 0.1]]), 'b1': array([[0.],\n       [0.]]), 'W2': array([[0.1],\n       [0.1]]), 'b2': array([[0.]])}\nFor row = 1\n{'W1': array([[0.10531456, 0.10531456],\n       [0.10531456, 0.10531456]]), 'b1': array([[0.00066432],\n       [0.00066432]]), 'W2': array([[0.1384],\n       [0.1384]]), 'b2': array([[0.1432]])}\nFor row = 2\n{'W1': array([[0.11388934, 0.11633927],\n       [0.11450447, 0.11713016]]), 'b1': array([[0.00188929],\n       [0.00197716]]), 'W2': array([[0.18480024],\n       [0.19805745]]), 'b2': array([[0.20468605]])}\nFor row = 3\n{'W1': array([[0.12563982, 0.13592341],\n       [0.12858742, 0.14060174]]), 'b1': array([[0.0038477 ],\n       [0.00432432]]), 'W2': array([[0.234837  ],\n       [0.28145205]]), 'b2': array([[0.28979151]])}\nFor row = 4\n{'W1': array([[0.13929845, 0.16870412],\n       [0.14775434, 0.18660235]]), 'b1': array([[0.00657943],\n       [0.00815771]]), 'W2': array([[0.28308604],\n       [0.39724975]]), 'b2': array([[0.40689956]])}\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"# epochs implementation\n\nparameters = initialize_parameters([2,2,1])\nepochs = 5\n\nfor i in range(epochs):\n\n  Loss = []\n\n  for j in range(df.shape[0]):\n\n    X = df[['cgpa', 'profile_score']].values[j].reshape(2,1) # Shape(no of features, no. of training example)\n    y = df[['lpa']].values[j][0]\n\n    # Parameter initialization\n\n\n    y_hat,A1 = L_layer_forward(X,parameters)\n    y_hat = y_hat[0][0]\n\n    update_parameters(parameters,y,y_hat,A1,X)\n\n    Loss.append((y-y_hat)**2)\n\n  print('Epoch - ',i+1,'Loss - ',np.array(Loss).mean())\n\nparameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:48:20.714622Z","iopub.execute_input":"2025-09-05T07:48:20.714956Z","iopub.status.idle":"2025-09-05T07:48:20.753485Z","shell.execute_reply.started":"2025-09-05T07:48:20.714930Z","shell.execute_reply":"2025-09-05T07:48:20.752532Z"}},"outputs":[{"name":"stdout","text":"Epoch -  1 Loss -  14.352737671449324\nEpoch -  2 Loss -  8.505990794958981\nEpoch -  3 Loss -  3.970155088746311\nEpoch -  4 Loss -  1.9056619001668114\nEpoch -  5 Loss -  1.2271843329692622\n","output_type":"stream"},{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"{'W1': array([[0.27490304, 0.41644747],\n        [0.3479265 , 0.55577451]]),\n 'b1': array([[0.02990073],\n        [0.04276587]]),\n 'W2': array([[0.5853851 ],\n        [0.93136799]]),\n 'b2': array([[0.93467989]])}"},"metadata":{}}],"execution_count":70}]}